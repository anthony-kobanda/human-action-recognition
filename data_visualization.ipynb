{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualization of the NTU RGB+D Action Recognition Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Initialization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *1.1. Imports*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to fill the requirement.txt file we use the following line of code:\n",
    "# import session_info\n",
    "# session_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *1.2. Data Loading*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2D_dir = \"data/nturgbd60_skeletons_2D/\"\n",
    "data3D_dir = \"data/nturgbd60_skeletons_3D/\"\n",
    "\n",
    "data2D_files = os.listdir(data2D_dir)\n",
    "data3D_files = os.listdir(data3D_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/actions.txt\", 'r') as actions_file:\n",
    "    actions = [line.replace('\\n', '') for line in actions_file.readlines()]\n",
    "    actions_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [i for i in range(60)]\n",
    "# for i,elem in enumerate(classes):\n",
    "#    print(\"class {} : {}\".format(i, actions[elem]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanActionDataset2D(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir, data_files, classes, flatten=False):\n",
    "        self.data_dir = data_dir\n",
    "        self.data_files = [data_file for data_file in data_files if int(data_file[17:-4])-1 in classes]\n",
    "        self.classes = classes\n",
    "        self.flatten =  flatten\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tensor = torch.Tensor(np.load(self.data_dir + self.data_files[idx]))\n",
    "        tensor = tensor.reshape((tensor.shape[0], tensor.shape[1]*tensor.shape[2]))\n",
    "        label = self.classes.index(int(self.data_files[idx][17:-4])-1)\n",
    "        return (tensor, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanActionDataset3D(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir, data_files, classes, flatten=False):\n",
    "        self.data_dir = data_dir\n",
    "        self.data_files = [data_file for data_file in data_files if int(data_file[17:-4])-1 in classes]\n",
    "        self.classes = classes\n",
    "        self.flatten =  flatten\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tensor = torch.Tensor(np.load(self.data_dir + self.data_files[idx]))\n",
    "        tensor = tensor.reshape((tensor.shape[0], tensor.shape[1]*tensor.shape[2]))\n",
    "        label = self.classes.index(int(self.data_files[idx][17:-4])-1)\n",
    "        return (tensor, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAD2D = HumanActionDataset2D(data2D_dir, data2D_files, classes)\n",
    "HAD3D = HumanActionDataset3D(data3D_dir, data3D_files, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Create Images**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder:\n",
    "\n",
    "![skeleton](./assets/skeleton.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequences of joints to display the members of the squeletons (add +1 to find the corresponding joints in the above graphic)\n",
    "\n",
    "bust_joints = [0, 1, 20, 2, 3]\n",
    "arm_joints = [23, 24, 11, 10, 9, 8, 20, 4, 5, 6, 7, 22, 21]\n",
    "leg_joints = [19, 18, 17, 16, 0, 12, 13, 14, 15]\n",
    "\n",
    "body_parts = [bust_joints, arm_joints, leg_joints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_sequence(i, dataset2D=HAD2D, dataset3D=HAD3D):\n",
    "    \n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    * (int) i : index of the sample to consider\n",
    "    * dataset2D : dataset with the pixel information\n",
    "    * dataset3D : dataset with the space information (if not None we will consider the depth in the generated images)\n",
    "\n",
    "    output:\n",
    "    * output : sequence of images with, eventually, depth\n",
    "    \"\"\"\n",
    "    \n",
    "    tensor2D = dataset2D[i][0]\n",
    "    output = np.zeros((tensor2D.shape[0],25,3))\n",
    "    z_sequence = np.zeros((tensor2D.shape[0],25))\n",
    "\n",
    "    if dataset3D != None:\n",
    "        tensor3D = dataset3D[i][0]\n",
    "        z_sequence = np.array([[tensor3D[k,3*i+2] for i in range(25)] for k in range(tensor3D.shape[0])])     \n",
    "    \n",
    "    for m in range(tensor2D.shape[0]):\n",
    "        for n in range(25):\n",
    "            x = tensor2D[m,2*n].item()\n",
    "            y = tensor2D[m,2*n+1].item()\n",
    "            x = min(max(0,int(x)),1920)-1\n",
    "            y = min(max(0,int(y)),1080)-1\n",
    "            z = z_sequence[m,n].item()\n",
    "            output[m,n] = [x,y,z]\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_sequence_normalize(i, dataset2D=HAD2D, dataset3D=HAD3D):\n",
    "    \"\"\"\n",
    "    get sequence of images with, eventually, depth but also normalize the depth between 0 and 1\n",
    "    \"\"\"\n",
    "    image_sequence = get_image_sequence(i, dataset2D, dataset3D)\n",
    "    mini = image_sequence[:,:,2].min()\n",
    "    maxi = image_sequence[:,:,2].max()\n",
    "    if mini != maxi:\n",
    "        image_sequence[:,:,2] = (image_sequence[:,:,2]-mini)/(maxi-mini)\n",
    "    return image_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image(image_frame):\n",
    "\n",
    "    img = Image.new(\"RGB\", (1920,1080 ), color=\"black\")\n",
    "    for body_part in body_parts:\n",
    "        for i in range(len(body_part)-1):\n",
    "            a = image_frame[body_part[i]]\n",
    "            b = image_frame[body_part[i+1]]-a\n",
    "            n = 10\n",
    "            line = np.array([a+(i/n)*b for i in range(n)])\n",
    "            for i in range(len(line)-1):\n",
    "                x1,y1,z = line[i]\n",
    "                x2,y2,_ = line[i+1]\n",
    "                draw = ImageDraw.Draw(img)\n",
    "                color = tuple((int(255*z),0,int(255*(1-z))))\n",
    "                draw.line((x1,y1,x2,y2), fill=color,width=5)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=1920x1080 at 0x202BD455160>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example (first element of the dataset)\n",
    "create_image(get_image_sequence_normalize(15)[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gif(i, filepath, dataset2D=HAD2D, dataset3D=HAD3D, normalize=True):\n",
    "    if normalize:\n",
    "        image_sequence = get_image_sequence_normalize(i, dataset2D, dataset3D)\n",
    "    else:\n",
    "        image_sequence = get_image_sequence(i, dataset2D, dataset3D)\n",
    "    seq = [create_image(frame) for frame in image_sequence]\n",
    "    seq[0].save(filepath, save_all=True, append_images=seq[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"gifs\" not in os.listdir(\"./data/\"):\n",
    "    os.mkdir(\"./data/gifs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:16<00:00,  1.32it/s]\n"
     ]
    }
   ],
   "source": [
    "for index in tqdm(range(100)):\n",
    "    name = data2D_files[index][:-4]\n",
    "    if name+\".gif\" not in os.listdir(\"./data/gifs\"):\n",
    "        create_gif(index, \"./data/gifs/{}.gif\".format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "118508df3531a4baef22a353ae7891686b2f0c3ff24a04c6bb67baeaff15e974"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
